import time
from timeit import timeit, Timer

import numpy as np
import h5py
import scipy
from scipy.sparse import csr_matrix


def convert_mat_to_npz_file(mat_file:str, npz_file_out:str, time_steps:int):
    """Reads a mat file generated by saveEdgesForPython() and saves it as a npz file for online reachability analysis"""
    print('<convert_mat_to_npy_file> load file', mat_file)
    mat = h5py.File(mat_file, 'r')
    print('<convert_mat_to_npy_file> finished loading')

    data_dict = {}
    for key, value in mat.items():
        if not '#' in key:
            data_dict[key] = value[()]

    data_dict['n_time_steps'] = int(data_dict['n_time_steps'][0, 0])

    data_dict['dt'] = data_dict['dt'][0,0]
    data_dict['dx'] = data_dict['dx'][0,0]
    data_dict['dy'] = data_dict['dy'][0,0]
    data_dict['dvx'] = data_dict['dvx'][0,0]
    data_dict['dvy'] = data_dict['dvy'][0,0]
    data_dict['a_max_x'] = data_dict['a_max_x'][0,0]
    data_dict['a_max_y'] = data_dict['a_max_y'][0,0]
    data_dict['n_time_steps'] = data_dict['n_time_steps']

    parameters = {}
    parameters['dt'] = data_dict['dt']
    parameters['grid_x'] = data_dict['dx']
    parameters['grid_y'] = data_dict['dy']
    parameters['dvx'] = data_dict['dvx']
    parameters['dvy'] = data_dict['dvy']
    parameters['a_max_x'] = data_dict['a_max_x']
    parameters['a_max_y'] = data_dict['a_max_y']
    parameters['n_time_steps'] = data_dict['n_time_steps']
    parameters['grid_reference_ll'] = data_dict['grid_reference_ll']
    parameters['grid_reference_ur'] = data_dict['grid_reference_ur']


    matrices, projections, shape_4d = parse_sparse_csr(data_dict, time_steps)

    save_offline_data_to_npz(npz_file_out, matrices, projections, shape_4d, parameters, time_steps)


def save_offline_data_to_npz(filename, matrices:list, projections:list,shape_4d:list, parameters:dict, time_steps:int):
    kwargs = {}
    kwargs['parameters'] = parameters
    kwargs['delta_timestep'] = 1
    kwargs['nt'] = len(matrices[:time_steps])
    kwargs['shape_4d'] = np.hstack(shape_4d).transpose().astype('int')
    for t, mat in enumerate(matrices[:time_steps]):
        proj = projections[t]
        # kwargs['data' + str(t)] = mat.data
        kwargs['dt0_' + 'E_indices' + str(t)] = mat.indices
        kwargs['dt0_' + 'E_indptr' + str(t)] = mat.indptr
        kwargs['dt0_' + 'E_shape' + str(t)] = mat.shape

        kwargs['dt0_' + 'P_indices' + str(t)] = proj.indices
        kwargs['dt0_' + 'P_indptr' + str(t)] = proj.indptr
        kwargs['dt0_' + 'P_shape' + str(t)] = proj.shape

    # for t, reachability_matrix_dict_tmp in enumerate(reachset._reachability_matrix_offline_grandchildren_dict):
    #     for delta_timestep, csr in reachability_matrix_dict_tmp.items():
    #         kwargs['data_gr' + str(t) + '_' + str(delta_timestep)] = csr.data
    #         kwargs['indices_gr' + str(t) + '_' + str(delta_timestep)] = csr.indices
    #         kwargs['indptr_gr' + str(t) + '_' + str(delta_timestep)] = csr.indptr
    #         kwargs['shape_gr' + str(t) + '_' + str(delta_timestep)] = csr.shape

    np.savez(filename, **kwargs)


def parse_sparse_csr(data_dict, time_steps):
    time_steps = time_steps if time_steps != -1 else np.inf
    dt = data_dict['dt']
    edges = []
    projections = []
    shape_4d = []
    for t in range(0,min(data_dict['n_time_steps'], time_steps)):
        shape_4d.append(data_dict['shape_4d_' + str(t)].reshape([4,1]))
        row = (data_dict['E_row_' + str(t)]).flatten()
        col = (data_dict['E_col_' + str(t)]).flatten()
        data = np.ones_like(row)
        shape = (int(data_dict['E_shape_' + str(t)][0]), int(data_dict['E_shape_' + str(t)][1]))
        tmp = csr_matrix((data,(row,col)), shape)
        edges.append(tmp)

        row = (data_dict['P_row_' + str(t)]).flatten()
        col = (data_dict['P_col_' + str(t)]).flatten()
        data = np.ones_like(row)
        shape = (int(data_dict['P_shape_' + str(t)][0]), int(data_dict['P_shape_' + str(t)][1]))
        tmp = csr_matrix((data, (row, col)), shape)
        projections.append(tmp)

    # for t in range(data_dict['n_time_steps']):
    #     for delta_timestep in range(dt):
    #         if 'data_gr' + str(t) + '_' + str(delta_timestep) in data_dict:
    #             tmp = csr_matrix((data_dict['data_gr' + str(t) + '_' + str(delta_timestep)],
    #                               data_dict['indices_gr' + str(t) + '_' + str(delta_timestep)],
    #                               data_dict['indptr_gr' + str(t) + '_' + str(delta_timestep)]),
    #                               data_dict['shape_gr' + str(t) + '_' + str(delta_timestep)])
    #             matrices.append(tmp)
    return edges, projections, shape_4d


def load_sparse_csr(filename):
    data = np.load(filename, allow_pickle=True)
    # dt = data['dt']
    matrices = []
    projections = []
    for t in range(data['nt']):
        tmp = csr_matrix((np.ones_like(data['dt0_' + 'E_indices' + str(t)]),
                          data['dt0_' + 'E_indices' + str(t)],
                          data['dt0_' + 'E_indptr' + str(t)]),
                          data['dt0_' + 'E_shape' + str(t)])
        matrices.append(tmp)

        tmp = csr_matrix((np.ones_like(data['dt0_' + 'P_indices' + str(t)]),
                          data['dt0_' + 'P_indices' + str(t)],
                          data['dt0_' + 'P_indptr' + str(t)]),
                         data['dt0_' + 'P_shape' + str(t)])
        projections.append(tmp)

    # for t in range(data['nt']):
    #     for delta_timestep in range(dt):
    #         if 'data_gr' + str(t) + '_' + str(delta_timestep) in data:
    #             tmp = csr_matrix((data['data_gr' + str(t) + '_' + str(delta_timestep)],
    #                               data['indices_gr' + str(t) + '_' + str(delta_timestep)],
    #                               data['indptr_gr' + str(t) + '_' + str(delta_timestep)]),
    #                              data['shape_gr' + str(t) + '_' + str(delta_timestep)])
    #             matrices.append(tmp)
    return matrices, data['parameters']


if __name__ == '__main__':
    time_steps = 30
    convert_mat_to_npz_file('/home/klischat/GIT_REPOS/out/pruning/edges.mat','/home/klischat/GIT_REPOS/out/pruning/edges_conv_30', time_steps)
    t0 = time.time()
    load_sparse_csr('/home/klischat/GIT_REPOS/out/pruning/edges_conv.npz')
    print(time.time()-t0)

    # def mult_sparse(n, n_next):
    #     adj = scipy.sparse.random(n_next, n, density=0.0001, format='csr')
    #     adj_bool = adj.toarray()
    #     adj_bool = adj_bool>0
    #     adj_bool_s = scipy.sparse.csr_matrix(adj_bool)
    #     adj_bool_i = scipy.sparse.csr_matrix(adj_bool.astype('int'))
    #     print('num',np.sum(adj))
    #     r = scipy.sparse.random(n, 1, density=0.3, format='csr')
    #     r_bool = r.toarray()
    #     r_bool = r > 0
    #     r_bool_s = scipy.sparse.csr_matrix(r_bool)
    #     r_bool_i = scipy.sparse.csr_matrix(r_bool.astype('int16'))
    #
    #     t0 = time.time()
    #     for _ in range(40):
    #         r_next = adj_bool_s * r_bool_s
    #         # rnxet =
    #
    #     print((time.time()-t0)/40)
    #
    #     t0 = time.time()
    #     for _ in range(40):
    #         r_next_bool = adj_bool * r_bool
    #         # rnxet =
    #
    #     print((time.time()-t0)/40)
    #
    #     adj
    #
    # n = 8000
    # n_next = 10000
    #
    # mult_sparse(n, n_next)


